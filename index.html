<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sudipta Paul</title>
  
  <meta name="author" content="Sudipta Paul">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <link rel   = "stylesheet" href    ="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sudipta Paul</name>
              </p>
              <p>I am a fifth year PhD student in the <a href="https://vcg.ece.ucr.edu/"> Video Computing Group (VCG)</a>, at the University of California, Riverside, advised by <a href = "https://vcg.ece.ucr.edu/amit"> Dr. Amit K. Roy-Chowdhury</a>. My research interests include Computer Vision, Deep Learning, and Multi-modal Learning.</p>
              <p> I completed my undergraduate in Electrical and Electronic Engineering from Bangladesh University of Engineering and Technology, Dhaka, Bangladesh where I worked with <a href="https://mahbubur.buet.ac.bd/"> Dr. SM Mahbubur Rahman</a> on problems related to affective computing using multimodal data. During Summer 2019, I have worked as a research intern at <a href="https://mayachitra.com/Mayachitra"> Mayachitra</a> in Santa Barbara, CA, USA where the work was focused on traffic activity analysis.  

              </p>
              <p style="text-align:center">
                <a href="spaul007@ucr.edu">Email</a> &nbsp/&nbsp
                <a href="https://www.dropbox.com/s/rqfejkhp839m1u9/Sudipta_cv.pdf?dl=0">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=LKvuP0YAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/sudipta-paul-80761b86/">LinkedIn</a>  
                
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/web_pic_round.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/web_pic_round.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Interests</heading>
              <p>
                I'm interested in computer vision, machine learning, deep learning, multi-modal learning. Much of my research is about working with multi-modal data to learn the correspondance between different modalities specifically video and text. I also worked on utilizing contextual information to add robustness against label noise.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Updates</heading>
              <p>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> July 2022: Paper accepted in ECCV 2022<br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> Feb. 2022: Paper accepted in Journal of
Big Data <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> Oct. 2021: Paper accepted in T-IP <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> June 2021: Joined Mitsubishi Electric Research Laboratories as research intern <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> Aug. 2020: Paper accepted in ECCV 2020 <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> May 2020: Paper accepted in ICASSP 2020 <br>
                &nbsp <i class="fa fa-share-alt" style="font-size:12px"></i> June 2019: Joined Mayachitra as research intern
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                <a href="data/7667.pdf">
                <papertitle>Text-based Temporal Localization of Novel Events</papertitle></a><br>
                <strong>Sudipta Paul<strong>, Niluthpol Chowdhury Mithun, Amit K Roy-Chowdhury<br>
                European Conference on Computer Vision (ECCV), 2022</em>
              </p>
              <p>
                <a href="data/corpus_tip.pdf">
                <papertitle>Text-based Localization of moments in a Video Corpus</papertitle></a><br>
                <strong>Sudipta Paul<strong>, Niluthpol Chowdhury Mithun, Amit K Roy-Chowdhury<br>
                IEEE Transactions on Image Processing, 2021</em>
              </p>
              <p>
                <a href="data/task_agnostic.pdf">
                <papertitle>Task-agnostic representation learning of multimodal twitter data for downstream applications</papertitle></a><br>
                Ryan Rivas, <strong>Sudipta Paul<strong>, Vagelis Hristidis, Evangelos E Papalexakis, Amit K Roy-Chowdhury<br>
                Journal of Big Data, 2022</em>
              </p>
              <p>
                <a href="data/shasha_eccv.pdf">
                <papertitle>Connecting the Dots: Detecting Adversarial Perturbations Using Context Inconsistency</papertitle></a><br>
                Shasha Li, Shitong Zhu, <strong>Sudipta Paul<strong>, Amit Roy-Chowdhury, Chengyu Song, Srikanth Krishnamurthy, Ananthram Swami, Kevin S Chan<br>
                <em>European Conference on Computer Vision (ECCV), 2020</em>
              </p>
              <p>
                <a href="data/pairwise_activity.pdf">
                <papertitle>Complex Pairwise Activity Analysis Via Instance Level Evolution Reasoning</papertitle></a><br>
                <strong>Sudipta Paul<strong>, Carlos Torres, Shivkumar Chandrasekaran, Amit K Roy-Chowdhury<br>
                <em>International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2020</em>
              </p>
              <p>
                <a href="data/mutual_affective.pdf">
                <papertitle>Mutual information-based selection of audiovisual affective features to predict instantaneous emotional state</papertitle></a><br>
                <strong>Sudipta Paul<strong>, Nurani Saoda, SM Mahbubur Rahman, Dimitrios Hatzinakos<br>
                <em>International Conference on Computer and Information Technology (ICCIT), 2016</em>
              </p>
              <p>
                <a href="data/context_tip.pdf">
                <papertitle>Exploiting Context for Robustness to Label Noise in Active Learning</papertitle></a><br>
                <strong>Sudipta Paul<strong>, Shivkumar Chandrasekaran, B.S. Manjunath, Amit K Roy-Chowdhury<br>
                ArXiv Preprint
              </p>
              
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr><td><br><p align="right"><font size="2">
          You can find the template <a href="http://www.cs.berkeley.edu/~barron/">here</a>.
          </font></p></td></tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
